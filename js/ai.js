/********************************************************************************************* 

PRSM Participatory System Mapper 

MIT License

Copyright (c) [2022] Nigel Gilbert email: prsm@prsm.uk

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


This module generates responses using an LLM.  
********************************************************************************************//*
 * Invoke AWS Bedrock LLM model in guest mode using AWS SDK for JavaScript
 *
 * This is a simplified version of the code example in the blog post:
 * https://github.com/alankrantas/aws-sdk-js-bedrock-llm-example/blob/main/README.md
 * See the blog post for details about how to set up the AWS environment.
 */

// bedrock resource
const region = "eu-west-2"
const cognitoIdentityPoolId = `eu-west-2:fb5bdf50-29b1-4de5-a33e-3937ef1cef58`
const bedrockRoleArn =
    "arn:aws:iam::162252354798:role/service-role/Bedrock_access"

// select model 
const modelId = "meta.llama3-8b-instruct-v1:0"

// set the system prompt
const systemPrompt = [{
    text: `Please answer questions using Markdown format.  
    Structure the answer in these sections: introduction, bullet points, summary.
    Do not include a title. Start the answer with the sentence, formatted in italics: 
    This text has been generated by AI. Answer concisely in no more than 200 words`
}]

// ================================================================================

import {
    CognitoIdentityClient,
    GetIdCommand,
    GetOpenIdTokenCommand,
} from "@aws-sdk/client-cognito-identity"
import {
    STSClient,
    AssumeRoleWithWebIdentityCommand,
} from "@aws-sdk/client-sts"
import {
    BedrockRuntimeClient,
    ConverseCommand,
} from "@aws-sdk/client-bedrock-runtime"
//import markdownToDelta from 'markdown-to-quill-delta'
import { MarkdownToQuill } from 'md-to-quill-delta';

async function chat(userMessage) {
    try {
        const config = { region: region }

        // get guest identity id

        const cognitoClient = new CognitoIdentityClient(config)
        const idResponse = await cognitoClient.send(
            new GetIdCommand({ IdentityPoolId: cognitoIdentityPoolId })
        )
        const id = idResponse.IdentityId

        // get access token
        const tokenResponse = await cognitoClient.send(
            new GetOpenIdTokenCommand({ IdentityId: id })
        )
        const token = tokenResponse.Token

        // get credential with session policy
        const stsClient = new STSClient(config)
        const credentialsResponse = await stsClient.send(
            new AssumeRoleWithWebIdentityCommand({
                RoleArn: bedrockRoleArn,
                WebIdentityToken: token,
                RoleSessionName: "bedrock_session",
            })
        )
        const credentials = credentialsResponse.Credentials

        // get bedrock client using the credential

        const bedrockClient = new BedrockRuntimeClient({
            region: region,
            credentials: {
                accessKeyId: credentials.AccessKeyId,
                secretAccessKey: credentials.SecretAccessKey,
                expiration: credentials.Expiration,
                sessionToken: credentials.SessionToken,
            },
        })

        const conversation = [
            {
                role: "user",
                content: [{ text: userMessage }],
            },
        ]

        // Create a command with the model ID, the message, and a basic configuration.
        const command = new ConverseCommand({
            modelId,
            messages: conversation,
            system: systemPrompt,
            inferenceConfig: { maxTokens: 512, temperature: 0.5, topP: 0.9 },
        })

        // Send the command to the model and wait for the response
        const response = await bedrockClient.send(command)

        // Extract and return the response text.
        const responseText = response.output.message.content[0].text
        console.log(response)
        return responseText
    } catch (err) {
        console.log(`ERROR: Can't invoke '${modelId}'. Reason: ${err}`)
    }
}
export async function getAIresponse(fromFactorLabel, toFactorLabel) {
    let markdown = await chat(`Explain the causal link between ${fromFactorLabel} and ${toFactorLabel}`)
    //return /* markdownToDelta(markdown) */ markdown
    const converter = new MarkdownToQuill({ debug: false });
    return converter.convert(markdown);
}
